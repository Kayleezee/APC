% PREAMBLE
%%%%%%%%%%
%%%%%%%%%%

\documentclass[DIV=12,oneside,a4paper]{scrartcl}

% PACKAGES
%%%%%%%%%%
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{pgf}
\usepackage{placeins}
\usepackage{listings}


% DOCUMENT
%%%%%%%%%%
%%%%%%%%%%

\begin{document}

%%%%%%%
% TITLE
%%%%%%%

\title{Exercise Sheet II}
\subject{Advanced Parallel Computing}
\author{Klaus Naumann \& Christoph Klein}
\maketitle

%%%%%%%
% TABLE OF CONTENTS
%%%%%%%

%\newpage
%\tableofcontents
%\newpage

%%%%%%%
% PART 1
%%%%%%%%

\section{Review: The Future of Microprocessors}
The paper 'The Future of Microprocessors' from Kunle Ulukotun and Lance Hammond published
in September 2005 deals with the expected trend from Von-Neumann architectures to
Chip-Multiprocessor (CMP) design.

 In the first part the authors explain that the
uniprocessor developement reaches it's limits, because economic improvements
in power consumption, pipelining and superscalar issues are no longer realizable.
Therefore the only way to to keep performance increasing is to parallelize
the architectures. This seems to work well for server systems, as they have
to deal with parallel incoming user requests, but software developer still have to
adjust their code to the emerging parallel computer architectures.

The authors outline that a CMP design is beneficial, as inter thread communication
is faster and less power hungry. 

To our mind this paper describes the expected developement qualitatively in o good way.
As CMP designs are actually in our every day life the authors' prediction was correct,
which makes us accepting this paper.

\section{Review: Software and the Concurrency Revolution}
In their 2005 released paper "Software and the Concurrency Revolution" Sutter 
and Larus focus on concurrency and its importance for programmers and 
programming languages alike. Since the step in computer architecture from 
uniprocessors to multicore processors concurrency turned into a key to boost 
application performance on parallel architectures. Though the benefits of 
concurrency in software development are foreseeable it demands an advanced 
knowledge of the underlying hardware architecture and programmers to think in 
an unusual way.

Sutter and Luras outline the importance of separating applications in hundreds 
of tasks to gain performance in applications. The industry has to create new 
parallel-focused constructs as languages and tools to exploit the parallel 
hardware and make parallel applications understandable and transparent. 
Furthermore concurrency can increase stability and functionality of software.

We highly accept the opinion of the papers authors. Concurrency can highly 
increase the performance and stability of applications on a parallel architecture
as the difficulty without tools supporting the programmer in parallel application 
development.
      
%%%%%%%
% PART 2
%%%%%%%%

\section{Experiment: Pointer Chasing Benchmark}
In figure \ref{pointer_chasing_local} and \ref{pointer_chasing_remote}
you can see the pointer chasing benchmark's result on a home pc and on \emph{moore}
respectively. Some lines in figure \ref{pointer_chasing_remote} are truncated, because
the ssh connection was aborted. In the following we will discuss the graphs' behaviour for
the home pc. For low array sizes up to $2^{16}$ Bytes on the home pc the loading times
are very low, which shows us that the problem fits completely in the L1 cache. Thus the
L1 Cache seems to have 65 kB. The line with an array size of $2^{20}$ Bytes raises
up at a stride of $2^8$ Bytes, because at this point we have a saturation in
L1 and L2 caches. This fits well to the processor's data as it has four
L2 caches with 256 kB each ($2^{20}\approx 1048$ kB). When the lines up to
array sizes of $2^20$ Bytes drop down at a stride of $2^15$ Bytes we see
the L1 associativity. The bigger array sizes up to $2^{23}$ Bytes drop
down at a stride of $2^{20}$ Bytes due to L2 cache associativity.
For the three biggest array sizes we see a raise in loading time at a stride of
$2^16$ Bytes, because of increasing saturation of TLB misses. This indicates roughly
a page size of $2^{17}$ Bytes. The discussion of \emph{moore's} pointer chasing benchmark
as analog.

\begin{figure}
	\input{../part2_2/pointer_chasing.pgf}
	\label{pointer_chasing_local}
	\caption{Local pointer chasing Benchmark on home computer. The lines' colors indicate the
	         used arrays' sizes in Bytes. The system's processor was an Intel i5-760 with 
			 4 cores at 2.8 GHz and a L3 cache size of 8792 kB. Due to rounding errors
			 some loading times are negative.}
\end{figure}
\begin{figure}
	\input{../part2_2/pointer_chasing_remote.pgf}
	\label{pointer_chasing_remote}
	\caption{Pointer chasing Benchmark on \emph{moore}. The lines' colors indicate the
	         used arrays' sizes in Bytes. Some lines are of an unequal length as
			 the \texttt{ssh} connection to \emph{moore} broke during the experiment.} 
\end{figure}
%%%%%%%
% PART 3
%%%%%%%%

\section{Experiment: Mutli-threaded Load Bandwidth}

In figure \ref{threads_local} and \ref{threads_remote} we see 
an increase in bandwidth at low thread counts. But for very high
thread counts we spectate a decreasing bandwidth, which is due to
thread overhead. At a certain number of threads we reach the 
maximum bandwidth of the system, thus by increasing the 
thread count further, we gain an instruction overhead.

\begin{figure}
	\input{../part2_4/src/threads_local.pgf}
	\label{threads_local}
	\caption{Bandwidth with increasing number of threads on home pc.}
\end{figure}

\begin{figure}
	\input{../part2_4/src/threads_remote.pgf}
	\label{threads_remote}
	\caption{Bandwidth with increasing number of threads on \emph{moore}.}

\end{figure}

\end{document}
